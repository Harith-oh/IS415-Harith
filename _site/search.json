[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "IS415-Harith",
    "section": "",
    "text": "Welcome to IS415 Geospatial Analytics and Applications\nThis is the course website of IS415 I study this term. You will find my coursework on this website."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "",
    "text": "In this section, I will install and load tidyverse and sf packages.\n\npacman::p_load(tidyverse, sf)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-the-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-the-geospatial-data",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Plotting the Geospatial Data",
    "text": "Plotting the Geospatial Data\n\nplot(mpsz)\n\n\n\n\n#Importing polyline feature data in shapefile form\n\ncyclingpath = st_read(dsn = \"Data/geospatial\", \n                         layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `C:\\Harith-oh\\IS415-Harith\\Hands-on_Ex\\Hands-on_Ex01\\Data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2248 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42626.09 ymax: 48948.15\nProjected CRS: SVY21\n\n\n#Importing GIS data in kml format\n\npreschool = st_read(\"Data/geospatial/preschools-location.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\Harith-oh\\IS415-Harith\\Hands-on_Ex\\Hands-on_Ex01\\Data\\geospatial\\preschools-location.kml' \n  using driver `KML'\nSimple feature collection with 1925 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n#Working with st_geometry()\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\n#Working with glimpse()\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO <int> 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  <chr> \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  <chr> \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     <chr> \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N <chr> \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C <chr> \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   <chr> \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   <chr> \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    <chr> \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D <date> 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     <dbl> 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     <dbl> 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng <dbl> 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area <dbl> 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   <MULTIPOLYGON [m]> MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\n#Working with head()\n\nhead(mpsz, n=5)\n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n\n\n\nplot(st_geometry(mpsz))\n\n\n\n\n\nplot(mpsz[\"PLN_AREA_N\"])\n\n\n\n\n#Assigning EPSG code to a simple feature data frame\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\n\nmpsz3414 <- st_set_crs(mpsz, 3414)\n\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\npreschool3414 <- st_transform(preschool, crs = 3414)\n\n#Importing the aspatial data\n\nlistings <-read_csv((\"Data/aspatial/listings.csv\"))\n\n\nlist(listings)\n\n[[1]]\n# A tibble: 4,161 × 18\n       id name     host_id host_…¹ neigh…² neigh…³ latit…⁴ longi…⁵ room_…⁶ price\n    <dbl> <chr>      <dbl> <chr>   <chr>   <chr>     <dbl>   <dbl> <chr>   <dbl>\n 1  50646 Pleasan…  227796 Sujatha Centra… Bukit …    1.33    104. Privat…    80\n 2  71609 Ensuite…  367042 Belinda East R… Tampin…    1.35    104. Privat…   145\n 3  71896 B&B  Ro…  367042 Belinda East R… Tampin…    1.35    104. Privat…    85\n 4  71903 Room 2-…  367042 Belinda East R… Tampin…    1.35    104. Privat…    85\n 5 275344 15 mins… 1439258 Kay     Centra… Bukit …    1.29    104. Privat…    49\n 6 289234 Booking…  367042 Belinda East R… Tampin…    1.34    104. Privat…   184\n 7 294281 5 mins … 1521514 Elizab… Centra… Newton     1.31    104. Privat…    79\n 8 324945 Cozy Bl… 1439258 Kay     Centra… Bukit …    1.29    104. Privat…    49\n 9 330089 Cozy Bl… 1439258 Kay     Centra… Bukit …    1.29    104. Privat…    55\n10 330095 10 mins… 1439258 Kay     Centra… Bukit …    1.29    104. Privat…    55\n# … with 4,151 more rows, 8 more variables: minimum_nights <dbl>,\n#   number_of_reviews <dbl>, last_review <date>, reviews_per_month <dbl>,\n#   calculated_host_listings_count <dbl>, availability_365 <dbl>,\n#   number_of_reviews_ltm <dbl>, license <chr>, and abbreviated variable names\n#   ¹​host_name, ²​neighbourhood_group, ³​neighbourhood, ⁴​latitude, ⁵​longitude,\n#   ⁶​room_type\n\n\n\nlistings_sf <- st_as_sf(listings, \n                       coords = c(\"longitude\", \"latitude\"),\n                       crs=4326) %>%\n  st_transform(crs = 3414)\n\n\nglimpse(listings_sf)\n\nRows: 4,161\nColumns: 17\n$ id                             <dbl> 50646, 71609, 71896, 71903, 275344, 289…\n$ name                           <chr> \"Pleasant Room along Bukit Timah\", \"Ens…\n$ host_id                        <dbl> 227796, 367042, 367042, 367042, 1439258…\n$ host_name                      <chr> \"Sujatha\", \"Belinda\", \"Belinda\", \"Belin…\n$ neighbourhood_group            <chr> \"Central Region\", \"East Region\", \"East …\n$ neighbourhood                  <chr> \"Bukit Timah\", \"Tampines\", \"Tampines\", …\n$ room_type                      <chr> \"Private room\", \"Private room\", \"Privat…\n$ price                          <dbl> 80, 145, 85, 85, 49, 184, 79, 49, 55, 5…\n$ minimum_nights                 <dbl> 92, 92, 92, 92, 60, 92, 92, 60, 60, 60,…\n$ number_of_reviews              <dbl> 18, 20, 24, 47, 14, 12, 133, 17, 12, 3,…\n$ last_review                    <date> 2014-12-26, 2020-01-17, 2019-10-13, 20…\n$ reviews_per_month              <dbl> 0.18, 0.15, 0.18, 0.34, 0.11, 0.10, 1.0…\n$ calculated_host_listings_count <dbl> 1, 6, 6, 6, 44, 6, 7, 44, 44, 44, 6, 7,…\n$ availability_365               <dbl> 365, 340, 265, 365, 296, 285, 365, 181,…\n$ number_of_reviews_ltm          <dbl> 0, 0, 0, 0, 1, 0, 0, 3, 2, 0, 1, 0, 0, …\n$ license                        <chr> NA, NA, NA, NA, \"S0399\", NA, NA, \"S0399…\n$ geometry                       <POINT [m]> POINT (22646.02 35167.9), POINT (…\n\n\n#buffering\n\nbuffer_cycling <- st_buffer(cyclingpath, \n                               dist=5, nQuadSegs = 30)\n\n\nbuffer_cycling$AREA <- st_area(buffer_cycling)\n\n\nsum(buffer_cycling$AREA)\n\n1556978 [m^2]\n\n\n#Point-in-polygon count\n\nmpsz3414$`PreSch Count`<- lengths(st_intersects(mpsz3414, preschool3414))\n\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    3.00    5.96    9.00   58.00 \n\n\n\ntop_n(mpsz3414, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           58\n\n\n#Calculate the density of pre-school by planning subzone\n\nmpsz3414$Area <- mpsz3414 %>%\n  st_area()\n\n\nmpsz3414 <- mpsz3414 %>%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)\n\n#Explorotary Data Analysis(EDA)\n\nhist(mpsz3414$`PreSch Density`)\n\n\n\n\n\nggplot(data=mpsz3414, \n       aes(x= as.numeric(`PreSch Density`)))+\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  labs(title = \"Are pre-school even distributed in Singapore?\",\n       subtitle= \"There are many planning sub-zones with a single pre-school, on the other hand, \\nthere are two planning sub-zones with at least 20 pre-schools\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Frequency\")\n\n\n\n\n#Using ggplot2 method, plot a scatterplot showing the relationship between Pre-school Density and Pre-school Count.\n\nggplot(data=mpsz3414, \n       aes(y = `PreSch Count`, \n           x= as.numeric(`PreSch Density`)))+\n  geom_point(color=\"black\", \n             fill=\"light blue\") +\n  xlim(0, 40) +\n  ylim(0, 40) +\n  labs(title = \"\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Pre-school count\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex/In-class_Ex02.html",
    "href": "In-class_Ex/In-class_Ex/In-class_Ex02.html",
    "title": "In-class Exercise 2: Geospatial Data Wrangling",
    "section": "",
    "text": "Water is an important resource to mankind. Clean and accessible water is critical to human health. It provides a healthy environment, a sustainable economy, reduces poverty and ensures peace and security. Yet over 40% of the global population does not have access to sufficient clean water. By 2025, 1.8 billion people will be living in countries or regions with absolute water scarcity, according to UN-Water. The lack of water poses a major threat to several sectors, including food security. Agriculture uses about 70% of the world’s accessible freshwater.\nDeveloping countries are most affected by water shortages and poor water quality. Up to 80% of illnesses in the developing world are linked to inadequate water and sanitation. Despite technological advancement, providing clean water to the rural community is still a major development issues in many countries globally, especially countries in the Africa continent.\nTo address the issue of providing clean and sustainable water supply to the rural community, a global Water Point Data Exchange (WPdx) project has been initiated. The main aim of this initiative is to collect water point related data from rural areas at the water point or small water scheme level and share the data via WPdx Data Repository, a cloud-based data library. What is so special of this project is that data are collected based on WPDx Data Standard.\n\n\nGeospatial analytics hold tremendous potential to address complex problems facing society. In this study, you are tasked to apply appropriate geospatial data wrangling methods to prepare the data for water point mapping study. For the purpose of this study, Nigeria will be used as the study country.\n\n\n\nFor the purpose of this assignment, data from WPdx Global Data Repositories will be used. There are two versions of the data. They are: WPdx-Basic and WPdx+. You are required to use WPdx+ data set.\n\n\n\nNigeria Level-2 Administrative Boundary (also known as Local Government Area) polygon features GIS data will be used in this take-home exercise. The data can be downloaded either from The Humanitarian Data Exchange portal or geoBoundaries.\n\n\n\nThe specific tasks of this take-home exercise are as follows:\n\nUsing appropriate sf method, import the shapefile into R and save it in a simple feature data frame format. Note that there are three Projected Coordinate Systems of Nigeria, they are: EPSG: 26391, 26392, and 26303. You can use any one of them.\nUsing appropriate tidyr and dplyr methods, derive the proportion of functional and non-functional water point at LGA level.\nCombining the geospatial and aspatial data frame into simple feature data frame.\nVisualising the distribution of water point by using appropriate analytical visualisation methods."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex/In-class_Ex02.html#section",
    "href": "In-class_Ex/In-class_Ex/In-class_Ex02.html#section",
    "title": "In-class Exercise 2: Geospatial Data Wrangling",
    "section": "",
    "text": "The Data\n\nAspatial data\nFor the purpose of this assignment, data from WPdx Global Data Repositories will be used. There are two versions of the data. They are: WPdx-Basic and WPdx+. You are required to use WPdx+ data set.\n\n\nGeospatial data\nNigeria Level-2 Administrative Boundary (also known as Local Government Area) polygon features GIS data will be used in this take-home exercise. The data can be downloaded either from The Humanitarian Data Exchange portal or geoBoundaries."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex/In-class_Ex02.html#installing-and-loading-packages",
    "href": "In-class_Ex/In-class_Ex/In-class_Ex02.html#installing-and-loading-packages",
    "title": "In-class Exercise 2: Geospatial Data Wrangling",
    "section": "2.1 Installing and Loading Packages",
    "text": "2.1 Installing and Loading Packages\nFirstly, the code below will check if pacman has been installed. If it has not been installed, R will download and install it, before activating it for use during this session.\n\nif (!require('pacman', character.only = T)){\n  install.packages('pacman')\n}\nlibrary('pacman')\n\nNext, pacman assists us by helping us load R packages that we require, sf, tidyverse and funModeling.\n\npacman::p_load(sf, tidyverse, funModeling)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex/In-class_Ex02.html#geoboundaries-nigeria-level-2-administrative-boundary-dataset",
    "href": "In-class_Ex/In-class_Ex/In-class_Ex02.html#geoboundaries-nigeria-level-2-administrative-boundary-dataset",
    "title": "In-class Exercise 2: Geospatial Data Wrangling",
    "section": "2.2 geoBoundaries Nigeria Level-2 Administrative Boundary Dataset",
    "text": "2.2 geoBoundaries Nigeria Level-2 Administrative Boundary Dataset\n\n2.2.1 Importing geoBoundaries Nigeria Level-2 Administrative Boundary Dataset\nIn the code below, dsn specifies the filepath where the dataset is located and layer provides the filename of the dataset excluding the file extension.\n\ngbnigeria = st_read(dsn = \"data/Geospatial\", layer = \"geoBoundaries-NGA-ADM2\")\n\nReading layer `geoBoundaries-NGA-ADM2' from data source \n  `C:\\Harith-oh\\IS415-Harith\\In-class_Ex\\In-class_Ex\\data\\Geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 774 features and 5 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2.668534 ymin: 4.273007 xmax: 14.67882 ymax: 13.89442\nGeodetic CRS:  WGS 84\n\n\nFrom the above message, it tells us that the dataset contains multipolygon features, containing 774 multipolygon features and 5 fields in the gbnigeria simple feature data frame and is in the WGS84 geographic coordinates system.\nLet us check the other dataset from Humanitarian data exchange.\n\nnigeria = st_read(dsn = \"data/Geospatial\", layer = \"nga_admbnda_adm2_osgof_20190417\")\n\nReading layer `nga_admbnda_adm2_osgof_20190417' from data source \n  `C:\\Harith-oh\\IS415-Harith\\In-class_Ex\\In-class_Ex\\data\\Geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 774 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2.668534 ymin: 4.273007 xmax: 14.67882 ymax: 13.89442\nGeodetic CRS:  WGS 84\n\n\nFrom the above message, it tells us that the dataset contains multipolygon features, containing 774 multipolygon features and 16 fields in the gbnigeria simple feature data frame and is in the WGS84 geographic coordinates system.\nBy comparing both datasets, the dataset from Humanitarian Data Exchange is more favourable as we can tell which state the LGA area belongs too which will be beneficial for our analysis\n\n\n2.2.2 Checking the Coordinate Reference System\nIn the code below, we will check if the Coordinate Reference System has been specified correctly.\n\nst_crs(nigeria)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\nAs seen above, the file has been configured correctly, having a WGS84 Geographic Coordinate System which maps to EPSG:4326.\n\n\n2.2.3 Converting the Coordinate Reference System\nIn the code below, we will convert the Geographic Coordinate Reference System from WGS84 to EPSG:26391 Projected Coordinate System.\n\nnigeria26391 <- st_transform(nigeria, crs = 26391)\n\n\nst_crs(nigeria26391)\n\nCoordinate Reference System:\n  User input: EPSG:26391 \n  wkt:\nPROJCRS[\"Minna / Nigeria West Belt\",\n    BASEGEOGCRS[\"Minna\",\n        DATUM[\"Minna\",\n            ELLIPSOID[\"Clarke 1880 (RGS)\",6378249.145,293.465,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4263]],\n    CONVERSION[\"Nigeria West Belt\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",4,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",4.5,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.99975,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",230738.26,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Engineering survey, topographic mapping.\"],\n        AREA[\"Nigeria - onshore west of 6°30'E, onshore and offshore shelf.\"],\n        BBOX[3.57,2.69,13.9,6.5]],\n    ID[\"EPSG\",26391]]\n\n\nAfter running the code, we can confirm that the data frame has been converted to EPSG:26391 Projected Coordinate System."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex/In-class_Ex02.html#wpdx-aspatial-data",
    "href": "In-class_Ex/In-class_Ex/In-class_Ex02.html#wpdx-aspatial-data",
    "title": "In-class Exercise 2: Geospatial Data Wrangling",
    "section": "2.3 WPdx + Aspatial Data",
    "text": "2.3 WPdx + Aspatial Data\n\n2.3.1 Importing WPdx + Aspatial Data\nSince WPdx+ data set is in csv format, we will use read_csv() of readr package to import Water_Point_Data_Exchange_-_PlusWPdx.csv and output it to an R object called wpdx.\n\nwpdx <- read_csv(\"data/Aspatial/Water_Point_Data_Exchange.csv\") %>%\n  filter(`#clean_country_name` == \"Nigeria\")\n\n\nlist(wpdx)\n\n[[1]]\n# A tibble: 95,008 × 70\n   row_id `#source`      #lat_…¹ #lon_…² #repo…³ #stat…⁴ #wate…⁵ #wate…⁶ #wate…⁷\n    <dbl> <chr>            <dbl>   <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 429068 GRID3             7.98    5.12 08/29/… Unknown <NA>    <NA>    Tapsta…\n 2 222071 Federal Minis…    6.96    3.60 08/16/… Yes     Boreho… Well    Mechan…\n 3 160612 WaterAid          6.49    7.93 12/04/… Yes     Boreho… Well    Hand P…\n 4 160669 WaterAid          6.73    7.65 12/04/… Yes     Boreho… Well    <NA>   \n 5 160642 WaterAid          6.78    7.66 12/04/… Yes     Boreho… Well    Hand P…\n 6 160628 WaterAid          6.96    7.78 12/04/… Yes     Boreho… Well    Hand P…\n 7 160632 WaterAid          7.02    7.84 12/04/… Yes     Boreho… Well    Hand P…\n 8 642747 Living Water …    7.33    8.98 10/03/… Yes     Boreho… Well    Mechan…\n 9 642456 Living Water …    7.17    9.11 10/03/… Yes     Boreho… Well    Hand P…\n10 641347 Living Water …    7.20    9.22 03/28/… Yes     Boreho… Well    Hand P…\n# … with 94,998 more rows, 61 more variables: `#water_tech_category` <chr>,\n#   `#facility_type` <chr>, `#clean_country_name` <chr>, `#clean_adm1` <chr>,\n#   `#clean_adm2` <chr>, `#clean_adm3` <chr>, `#clean_adm4` <chr>,\n#   `#install_year` <dbl>, `#installer` <chr>, `#rehab_year` <lgl>,\n#   `#rehabilitator` <lgl>, `#management_clean` <chr>, `#status_clean` <chr>,\n#   `#pay` <chr>, `#fecal_coliform_presence` <chr>,\n#   `#fecal_coliform_value` <dbl>, `#subjective_quality` <chr>, …\n\n\nOur output shows our wpdx tibble data frame consists of 97,478 rows and 74 columns. The useful fields we would be paying attention to is the #lat_deg and #lon_deg columns, which are in the decimal degree format. By viewing the Data Standard on wpdx’s website, we know that the latitude and longitude is in the wgs84 Geographic Coordinate System.\n\n\n2.3.2 Creating a Simple Feature Data Frame from an Aspatial Data Frame\nAs the geometry is available in wkt in the column New Georeferenced Column, we can use st_as_sfc() to import the geomtry\n\nwpdx$Geometry <- st_as_sfc(wpdx$`New Georeferenced Column`)\n\nAs there is no spatial data information, firstly, we assign the original projection when converting the tibble dataframe to sf. The original is wgs84 which is EPSG:4326.\n\nwpdx_sf <- st_sf(wpdx, crs=4326)\nwpdx_sf\n\nSimple feature collection with 95008 features and 70 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 2.707441 ymin: 4.301812 xmax: 14.21828 ymax: 13.86568\nGeodetic CRS:  WGS 84\n# A tibble: 95,008 × 71\n   row_id `#source`      #lat_…¹ #lon_…² #repo…³ #stat…⁴ #wate…⁵ #wate…⁶ #wate…⁷\n *  <dbl> <chr>            <dbl>   <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 429068 GRID3             7.98    5.12 08/29/… Unknown <NA>    <NA>    Tapsta…\n 2 222071 Federal Minis…    6.96    3.60 08/16/… Yes     Boreho… Well    Mechan…\n 3 160612 WaterAid          6.49    7.93 12/04/… Yes     Boreho… Well    Hand P…\n 4 160669 WaterAid          6.73    7.65 12/04/… Yes     Boreho… Well    <NA>   \n 5 160642 WaterAid          6.78    7.66 12/04/… Yes     Boreho… Well    Hand P…\n 6 160628 WaterAid          6.96    7.78 12/04/… Yes     Boreho… Well    Hand P…\n 7 160632 WaterAid          7.02    7.84 12/04/… Yes     Boreho… Well    Hand P…\n 8 642747 Living Water …    7.33    8.98 10/03/… Yes     Boreho… Well    Mechan…\n 9 642456 Living Water …    7.17    9.11 10/03/… Yes     Boreho… Well    Hand P…\n10 641347 Living Water …    7.20    9.22 03/28/… Yes     Boreho… Well    Hand P…\n# … with 94,998 more rows, 62 more variables: `#water_tech_category` <chr>,\n#   `#facility_type` <chr>, `#clean_country_name` <chr>, `#clean_adm1` <chr>,\n#   `#clean_adm2` <chr>, `#clean_adm3` <chr>, `#clean_adm4` <chr>,\n#   `#install_year` <dbl>, `#installer` <chr>, `#rehab_year` <lgl>,\n#   `#rehabilitator` <lgl>, `#management_clean` <chr>, `#status_clean` <chr>,\n#   `#pay` <chr>, `#fecal_coliform_presence` <chr>,\n#   `#fecal_coliform_value` <dbl>, `#subjective_quality` <chr>, …\n\n\nNext, we then convert the projection to the appropriate decimal based projection system.\n\nwpdx_sf <- wpdx_sf %>%\n  st_transform(crs = 26391)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex/In-class_Ex02.html#excluding-redundant-fields",
    "href": "In-class_Ex/In-class_Ex/In-class_Ex02.html#excluding-redundant-fields",
    "title": "In-class Exercise 2: Geospatial Data Wrangling",
    "section": "3.1 Excluding Redundant Fields",
    "text": "3.1 Excluding Redundant Fields\nAs the wpdx sf dataframe consist of many redundant field, we use select() to select the fields which we want to retain.\n\nnigeria26391 <- nigeria26391 %>%\n  select(c(3:4, 8:9))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex/In-class_Ex02.html#checking-for-duplicate-name",
    "href": "In-class_Ex/In-class_Ex/In-class_Ex02.html#checking-for-duplicate-name",
    "title": "In-class Exercise 2: Geospatial Data Wrangling",
    "section": "3.2 Checking for Duplicate Name",
    "text": "3.2 Checking for Duplicate Name\nIt is important to check for duplicate name in the data main data fields. Using duplicated(), we can flag out LGA names that might be duplicated as shown below:\n\nnigeria26391$ADM2_EN[duplicated(nigeria26391$ADM2_EN) == TRUE]\n\n[1] \"Bassa\"    \"Ifelodun\" \"Irepodun\" \"Nasarawa\" \"Obi\"      \"Surulere\"\n\n\nTo reduce duplication of LGA names, we will put the state names behind to make it more specific.\n\nnigeria26391$ADM2_EN[94] <- \"Bassa, Kogi\"\nnigeria26391$ADM2_EN[95] <- \"Bassa, Plateau\"\nnigeria26391$ADM2_EN[304] <- \"Ifelodun, Kwara\"\nnigeria26391$ADM2_EN[305] <- \"Ifelodun, Osun\"\nnigeria26391$ADM2_EN[355] <- \"Irepodun, Kwara\"\nnigeria26391$ADM2_EN[356] <- \"Ireopodun, Osun\"\nnigeria26391$ADM2_EN[519] <- \"Nasarawa, Kano\"\nnigeria26391$ADM2_EN[520] <- \"Nasarawa, Nasarawa\"\nnigeria26391$ADM2_EN[546] <- \"Obi, Benue\"\nnigeria26391$ADM2_EN[547] <- \"Obi, Nasarawa\"\nnigeria26391$ADM2_EN[693] <- \"Surulere, Lagos\"\nnigeria26391$ADM2_EN[694] <- \"Surulere, Oyo\"\n\nLet us check now if the duplication has been resolved.\n\nnigeria26391$ADM2_EN[duplicated(nigeria26391$ADM2_EN) == TRUE]\n\ncharacter(0)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex/In-class_Ex02.html#understanding-field-names",
    "href": "In-class_Ex/In-class_Ex/In-class_Ex02.html#understanding-field-names",
    "title": "In-class Exercise 2: Geospatial Data Wrangling",
    "section": "4.1 Understanding Field Names",
    "text": "4.1 Understanding Field Names\nFirst, let us have a look at the #status_clean column which stores the information about Functional and Non-Functional data points. The code below returns all values that were used in the column.\n\nfreq(data = wpdx_sf,\n     input = '#status_clean')\n\n\n\n\n                     #status_clean frequency percentage cumulative_perc\n1                       Functional     45883      48.29           48.29\n2                   Non-Functional     29385      30.93           79.22\n3                             <NA>     10656      11.22           90.44\n4      Functional but needs repair      4579       4.82           95.26\n5 Non-Functional due to dry season      2403       2.53           97.79\n6        Functional but not in use      1686       1.77           99.56\n7         Abandoned/Decommissioned       234       0.25           99.81\n8                        Abandoned       175       0.18           99.99\n9 Non functional due to dry season         7       0.01          100.00\n\n\nAs there might be issues performing mathematical calculations with NA labels, we will rename them to unknown.\nThe code below renames the column #status_clean to status_clean, select only the status_clean for manipulation and then replace all na values to unknown.\n\nwpdx_sf_nga <- wpdx_sf %>%\n  rename(status_clean = '#status_clean') %>%\n  select(status_clean) %>%\n  mutate(status_clean = replace_na(status_clean, \"unknown\"))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex/In-class_Ex02.html#filtering-data",
    "href": "In-class_Ex/In-class_Ex/In-class_Ex02.html#filtering-data",
    "title": "In-class Exercise 2: Geospatial Data Wrangling",
    "section": "4.2 Filtering Data",
    "text": "4.2 Filtering Data\nWith our previous knowledge, we can filter the data to obtain functional proportion counts in each LGA level. We will filter the wpdx_sf_nga dataframes to option functional and non-functional water points.\n\nwpdx_func <- wpdx_sf_nga %>% \n  filter(status_clean %in% \n           c(\"Functional\", \n             \"Functional but not in use\", \n             \"Functional but needs repair\"))\nwpdx_nonfunc <- wpdx_sf_nga %>% \n  filter(status_clean %in%\n          c(\"Abadoned/Decommissioned\", \n            \"Abandoned\",\n            \"Non-Functional due to dry season\",\n            \"Non-Functional\",\n            \"Non functional due to dry season\"))\nwpdx_unknown <- wpdx_sf_nga %>%\n  filter(status_clean == \"unknown\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex/In-class_Ex02.html#point-in-polygon-count",
    "href": "In-class_Ex/In-class_Ex/In-class_Ex02.html#point-in-polygon-count",
    "title": "In-class Exercise 2: Geospatial Data Wrangling",
    "section": "4.3 Point-in-polygon Count",
    "text": "4.3 Point-in-polygon Count\nUtilising st_intersects() of sf package and lengths, we check where each data point for the water point which fall inside each LGA. We do each calculation separation so we can cross check later to ensure all the values sum to the same total.\n\nnigeria_wp <- nigeria26391 %>%\n  mutate(`total_wp` = lengths(\n    st_intersects(nigeria26391, wpdx_sf_nga))) %>%\n  mutate(`wp_functional` = lengths(\n    st_intersects(nigeria26391, wpdx_func))) %>%\n  mutate(`wp_nonfunctional` = lengths(\n    st_intersects(nigeria26391, wpdx_nonfunc))) %>%\n  mutate(`wp_unknown` = lengths(\n    st_intersects(nigeria26391, wpdx_unknown)))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex/In-class_Ex02.html#saving-the-analytical-data-in-rds-format",
    "href": "In-class_Ex/In-class_Ex/In-class_Ex02.html#saving-the-analytical-data-in-rds-format",
    "title": "In-class Exercise 2: Geospatial Data Wrangling",
    "section": "4.4 Saving the Analytical Data in rds format",
    "text": "4.4 Saving the Analytical Data in rds format\nIn order to retain the sf data structure for subsequent analysis, we should save the sf dataframe into rds format.\n\nwrite_rds(nigeria_wp, \"Data/rds/nigeria_wp.rds\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex/In-class_Ex02.html#plotting-the-distribution-of-total-water-points-by-lga-in-histogram",
    "href": "In-class_Ex/In-class_Ex/In-class_Ex02.html#plotting-the-distribution-of-total-water-points-by-lga-in-histogram",
    "title": "In-class Exercise 2: Geospatial Data Wrangling",
    "section": "4.5 Plotting the Distribution of Total Water Points by LGA in Histogram",
    "text": "4.5 Plotting the Distribution of Total Water Points by LGA in Histogram\nNext, we will use mutate() of dplyr package to compute the proportion of Functional and Non- water points.\nThis is given by Functional Proportion = Functional Count / Total Count.\n\nggplot(data = nigeria_wp,\n       aes(x = total_wp)) +\n  geom_histogram(bins = 20,\n                 color = \"black\",\n                 fill = \"light blue\") +\n  geom_vline(aes(xintercept = mean(\n    total_wp, na.rm = T)),\n    color = \"red\",\n    linetype = \"dashed\",\n    size = 0.8) +\n  ggtitle(\"Distribution of total water points by LGA\") +\n  xlab(\"No. of water points\") +\n  ylab(\"No of\\nLGAs\") +\n  theme(axis.title.y = element_text(angle = 0))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02.html",
    "href": "In-class_Ex/In-class_Ex02.html",
    "title": "In-class Exercise 2: Geospatial Data Wrangling",
    "section": "",
    "text": "Water is an important resource to mankind. Clean and accessible water is critical to human health. It provides a healthy environment, a sustainable economy, reduces poverty and ensures peace and security. Yet over 40% of the global population does not have access to sufficient clean water. By 2025, 1.8 billion people will be living in countries or regions with absolute water scarcity, according to UN-Water. The lack of water poses a major threat to several sectors, including food security. Agriculture uses about 70% of the world’s accessible freshwater.\nDeveloping countries are most affected by water shortages and poor water quality. Up to 80% of illnesses in the developing world are linked to inadequate water and sanitation. Despite technological advancement, providing clean water to the rural community is still a major development issues in many countries globally, especially countries in the Africa continent.\nTo address the issue of providing clean and sustainable water supply to the rural community, a global Water Point Data Exchange (WPdx) project has been initiated. The main aim of this initiative is to collect water point related data from rural areas at the water point or small water scheme level and share the data via WPdx Data Repository, a cloud-based data library. What is so special of this project is that data are collected based on WPDx Data Standard.\n\n\nGeospatial analytics hold tremendous potential to address complex problems facing society. In this study, you are tasked to apply appropriate geospatial data wrangling methods to prepare the data for water point mapping study. For the purpose of this study, Nigeria will be used as the study country.\n\n\n\nFor the purpose of this assignment, data from WPdx Global Data Repositories will be used. There are two versions of the data. They are: WPdx-Basic and WPdx+. You are required to use WPdx+ data set.\n\n\n\nNigeria Level-2 Administrative Boundary (also known as Local Government Area) polygon features GIS data will be used in this take-home exercise. The data can be downloaded either from The Humanitarian Data Exchange portal or geoBoundaries.\n\n\n\nThe specific tasks of this take-home exercise are as follows:\n\nUsing appropriate sf method, import the shapefile into R and save it in a simple feature data frame format. Note that there are three Projected Coordinate Systems of Nigeria, they are: EPSG: 26391, 26392, and 26303. You can use any one of them.\nUsing appropriate tidyr and dplyr methods, derive the proportion of functional and non-functional water point at LGA level.\nCombining the geospatial and aspatial data frame into simple feature data frame.\nVisualising the distribution of water point by using appropriate analytical visualisation methods."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02.html#installing-and-loading-packages",
    "href": "In-class_Ex/In-class_Ex02.html#installing-and-loading-packages",
    "title": "In-class Exercise 2: Geospatial Data Wrangling",
    "section": "2.1 Installing and Loading Packages",
    "text": "2.1 Installing and Loading Packages\nFirstly, the code below will check if pacman has been installed. If it has not been installed, R will download and install it, before activating it for use during this session.\n\nif (!require('pacman', character.only = T)){\n  install.packages('pacman')\n}\nlibrary('pacman')\n\nNext, pacman assists us by helping us load R packages that we require, sf, tidyverse and funModeling.\n\npacman::p_load(sf, tidyverse, funModeling)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02.html#geoboundaries-nigeria-level-2-administrative-boundary-dataset",
    "href": "In-class_Ex/In-class_Ex02.html#geoboundaries-nigeria-level-2-administrative-boundary-dataset",
    "title": "In-class Exercise 2: Geospatial Data Wrangling",
    "section": "2.2 geoBoundaries Nigeria Level-2 Administrative Boundary Dataset",
    "text": "2.2 geoBoundaries Nigeria Level-2 Administrative Boundary Dataset\n\n2.2.1 Importing geoBoundaries Nigeria Level-2 Administrative Boundary Dataset\nIn the code below, dsn specifies the filepath where the dataset is located and layer provides the filename of the dataset excluding the file extension.\n\ngbnigeria = st_read(dsn = \"data/Geospatial\", layer = \"geoBoundaries-NGA-ADM2\")\n\nReading layer `geoBoundaries-NGA-ADM2' from data source \n  `C:\\Harith-oh\\IS415-Harith\\In-class_Ex\\data\\Geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 774 features and 5 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2.668534 ymin: 4.273007 xmax: 14.67882 ymax: 13.89442\nGeodetic CRS:  WGS 84\n\n\nFrom the above message, it tells us that the dataset contains multipolygon features, containing 774 multipolygon features and 5 fields in the gbnigeria simple feature data frame and is in the WGS84 geographic coordinates system.\nLet us check the other dataset from Humanitarian data exchange.\n\nnigeria = st_read(dsn = \"data/Geospatial\", layer = \"nga_admbnda_adm2_osgof_20190417\")\n\nReading layer `nga_admbnda_adm2_osgof_20190417' from data source \n  `C:\\Harith-oh\\IS415-Harith\\In-class_Ex\\data\\Geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 774 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2.668534 ymin: 4.273007 xmax: 14.67882 ymax: 13.89442\nGeodetic CRS:  WGS 84\n\n\nFrom the above message, it tells us that the dataset contains multipolygon features, containing 774 multipolygon features and 16 fields in the gbnigeria simple feature data frame and is in the WGS84 geographic coordinates system.\nBy comparing both datasets, the dataset from Humanitarian Data Exchange is more favourable as we can tell which state the LGA area belongs too which will be beneficial for our analysis\n\n\n2.2.2 Checking the Coordinate Reference System\nIn the code below, we will check if the Coordinate Reference System has been specified correctly.\n\nst_crs(nigeria)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\nAs seen above, the file has been configured correctly, having a WGS84 Geographic Coordinate System which maps to EPSG:4326.\n\n\n2.2.3 Converting the Coordinate Reference System\nIn the code below, we will convert the Geographic Coordinate Reference System from WGS84 to EPSG:26391 Projected Coordinate System.\n\nnigeria26391 <- st_transform(nigeria, crs = 26391)\n\n\nst_crs(nigeria26391)\n\nCoordinate Reference System:\n  User input: EPSG:26391 \n  wkt:\nPROJCRS[\"Minna / Nigeria West Belt\",\n    BASEGEOGCRS[\"Minna\",\n        DATUM[\"Minna\",\n            ELLIPSOID[\"Clarke 1880 (RGS)\",6378249.145,293.465,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4263]],\n    CONVERSION[\"Nigeria West Belt\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",4,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",4.5,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.99975,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",230738.26,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Engineering survey, topographic mapping.\"],\n        AREA[\"Nigeria - onshore west of 6°30'E, onshore and offshore shelf.\"],\n        BBOX[3.57,2.69,13.9,6.5]],\n    ID[\"EPSG\",26391]]\n\n\nAfter running the code, we can confirm that the data frame has been converted to EPSG:26391 Projected Coordinate System."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02.html#wpdx-aspatial-data",
    "href": "In-class_Ex/In-class_Ex02.html#wpdx-aspatial-data",
    "title": "In-class Exercise 2: Geospatial Data Wrangling",
    "section": "2.3 WPdx + Aspatial Data",
    "text": "2.3 WPdx + Aspatial Data\n\n2.3.1 Importing WPdx + Aspatial Data\nSince WPdx+ data set is in csv format, we will use read_csv() of readr package to import Water_Point_Data_Exchange_-_PlusWPdx.csv and output it to an R object called wpdx.\n\nwpdx <- read_csv(\"data/Aspatial/Water_Point_Data_Exchange.csv\") %>%\n  filter(`#clean_country_name` == \"Nigeria\")\n\n\nlist(wpdx)\n\n[[1]]\n# A tibble: 95,008 × 70\n   row_id `#source`      #lat_…¹ #lon_…² #repo…³ #stat…⁴ #wate…⁵ #wate…⁶ #wate…⁷\n    <dbl> <chr>            <dbl>   <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 429068 GRID3             7.98    5.12 08/29/… Unknown <NA>    <NA>    Tapsta…\n 2 222071 Federal Minis…    6.96    3.60 08/16/… Yes     Boreho… Well    Mechan…\n 3 160612 WaterAid          6.49    7.93 12/04/… Yes     Boreho… Well    Hand P…\n 4 160669 WaterAid          6.73    7.65 12/04/… Yes     Boreho… Well    <NA>   \n 5 160642 WaterAid          6.78    7.66 12/04/… Yes     Boreho… Well    Hand P…\n 6 160628 WaterAid          6.96    7.78 12/04/… Yes     Boreho… Well    Hand P…\n 7 160632 WaterAid          7.02    7.84 12/04/… Yes     Boreho… Well    Hand P…\n 8 642747 Living Water …    7.33    8.98 10/03/… Yes     Boreho… Well    Mechan…\n 9 642456 Living Water …    7.17    9.11 10/03/… Yes     Boreho… Well    Hand P…\n10 641347 Living Water …    7.20    9.22 03/28/… Yes     Boreho… Well    Hand P…\n# … with 94,998 more rows, 61 more variables: `#water_tech_category` <chr>,\n#   `#facility_type` <chr>, `#clean_country_name` <chr>, `#clean_adm1` <chr>,\n#   `#clean_adm2` <chr>, `#clean_adm3` <chr>, `#clean_adm4` <chr>,\n#   `#install_year` <dbl>, `#installer` <chr>, `#rehab_year` <lgl>,\n#   `#rehabilitator` <lgl>, `#management_clean` <chr>, `#status_clean` <chr>,\n#   `#pay` <chr>, `#fecal_coliform_presence` <chr>,\n#   `#fecal_coliform_value` <dbl>, `#subjective_quality` <chr>, …\n\n\nOur output shows our wpdx tibble data frame consists of 97,478 rows and 74 columns. The useful fields we would be paying attention to is the #lat_deg and #lon_deg columns, which are in the decimal degree format. By viewing the Data Standard on wpdx’s website, we know that the latitude and longitude is in the wgs84 Geographic Coordinate System.\n\n\n2.3.2 Creating a Simple Feature Data Frame from an Aspatial Data Frame\nAs the geometry is available in wkt in the column New Georeferenced Column, we can use st_as_sfc() to import the geomtry\n\nwpdx$Geometry <- st_as_sfc(wpdx$`New Georeferenced Column`)\n\nAs there is no spatial data information, firstly, we assign the original projection when converting the tibble dataframe to sf. The original is wgs84 which is EPSG:4326.\n\nwpdx_sf <- st_sf(wpdx, crs=4326)\nwpdx_sf\n\nSimple feature collection with 95008 features and 70 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 2.707441 ymin: 4.301812 xmax: 14.21828 ymax: 13.86568\nGeodetic CRS:  WGS 84\n# A tibble: 95,008 × 71\n   row_id `#source`      #lat_…¹ #lon_…² #repo…³ #stat…⁴ #wate…⁵ #wate…⁶ #wate…⁷\n *  <dbl> <chr>            <dbl>   <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 429068 GRID3             7.98    5.12 08/29/… Unknown <NA>    <NA>    Tapsta…\n 2 222071 Federal Minis…    6.96    3.60 08/16/… Yes     Boreho… Well    Mechan…\n 3 160612 WaterAid          6.49    7.93 12/04/… Yes     Boreho… Well    Hand P…\n 4 160669 WaterAid          6.73    7.65 12/04/… Yes     Boreho… Well    <NA>   \n 5 160642 WaterAid          6.78    7.66 12/04/… Yes     Boreho… Well    Hand P…\n 6 160628 WaterAid          6.96    7.78 12/04/… Yes     Boreho… Well    Hand P…\n 7 160632 WaterAid          7.02    7.84 12/04/… Yes     Boreho… Well    Hand P…\n 8 642747 Living Water …    7.33    8.98 10/03/… Yes     Boreho… Well    Mechan…\n 9 642456 Living Water …    7.17    9.11 10/03/… Yes     Boreho… Well    Hand P…\n10 641347 Living Water …    7.20    9.22 03/28/… Yes     Boreho… Well    Hand P…\n# … with 94,998 more rows, 62 more variables: `#water_tech_category` <chr>,\n#   `#facility_type` <chr>, `#clean_country_name` <chr>, `#clean_adm1` <chr>,\n#   `#clean_adm2` <chr>, `#clean_adm3` <chr>, `#clean_adm4` <chr>,\n#   `#install_year` <dbl>, `#installer` <chr>, `#rehab_year` <lgl>,\n#   `#rehabilitator` <lgl>, `#management_clean` <chr>, `#status_clean` <chr>,\n#   `#pay` <chr>, `#fecal_coliform_presence` <chr>,\n#   `#fecal_coliform_value` <dbl>, `#subjective_quality` <chr>, …\n\n\nNext, we then convert the projection to the appropriate decimal based projection system.\n\nwpdx_sf <- wpdx_sf %>%\n  st_transform(crs = 26391)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02.html#excluding-redundant-fields",
    "href": "In-class_Ex/In-class_Ex02.html#excluding-redundant-fields",
    "title": "In-class Exercise 2: Geospatial Data Wrangling",
    "section": "3.1 Excluding Redundant Fields",
    "text": "3.1 Excluding Redundant Fields\nAs the wpdx sf dataframe consist of many redundant field, we use select() to select the fields which we want to retain.\n\nnigeria26391 <- nigeria26391 %>%\n  select(c(3:4, 8:9))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02.html#checking-for-duplicate-name",
    "href": "In-class_Ex/In-class_Ex02.html#checking-for-duplicate-name",
    "title": "In-class Exercise 2: Geospatial Data Wrangling",
    "section": "3.2 Checking for Duplicate Name",
    "text": "3.2 Checking for Duplicate Name\nIt is important to check for duplicate name in the data main data fields. Using duplicated(), we can flag out LGA names that might be duplicated as shown below:\n\nnigeria26391$ADM2_EN[duplicated(nigeria26391$ADM2_EN) == TRUE]\n\n[1] \"Bassa\"    \"Ifelodun\" \"Irepodun\" \"Nasarawa\" \"Obi\"      \"Surulere\"\n\n\nTo reduce duplication of LGA names, we will put the state names behind to make it more specific.\n\nnigeria26391$ADM2_EN[94] <- \"Bassa, Kogi\"\nnigeria26391$ADM2_EN[95] <- \"Bassa, Plateau\"\nnigeria26391$ADM2_EN[304] <- \"Ifelodun, Kwara\"\nnigeria26391$ADM2_EN[305] <- \"Ifelodun, Osun\"\nnigeria26391$ADM2_EN[355] <- \"Irepodun, Kwara\"\nnigeria26391$ADM2_EN[356] <- \"Ireopodun, Osun\"\nnigeria26391$ADM2_EN[519] <- \"Nasarawa, Kano\"\nnigeria26391$ADM2_EN[520] <- \"Nasarawa, Nasarawa\"\nnigeria26391$ADM2_EN[546] <- \"Obi, Benue\"\nnigeria26391$ADM2_EN[547] <- \"Obi, Nasarawa\"\nnigeria26391$ADM2_EN[693] <- \"Surulere, Lagos\"\nnigeria26391$ADM2_EN[694] <- \"Surulere, Oyo\"\n\nLet us check now if the duplication has been resolved.\n\nnigeria26391$ADM2_EN[duplicated(nigeria26391$ADM2_EN) == TRUE]\n\ncharacter(0)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02.html#understanding-field-names",
    "href": "In-class_Ex/In-class_Ex02.html#understanding-field-names",
    "title": "In-class Exercise 2: Geospatial Data Wrangling",
    "section": "4.1 Understanding Field Names",
    "text": "4.1 Understanding Field Names\nFirst, let us have a look at the #status_clean column which stores the information about Functional and Non-Functional data points. The code below returns all values that were used in the column.\n\nfreq(data = wpdx_sf,\n     input = '#status_clean')\n\n\n\n\n                     #status_clean frequency percentage cumulative_perc\n1                       Functional     45883      48.29           48.29\n2                   Non-Functional     29385      30.93           79.22\n3                             <NA>     10656      11.22           90.44\n4      Functional but needs repair      4579       4.82           95.26\n5 Non-Functional due to dry season      2403       2.53           97.79\n6        Functional but not in use      1686       1.77           99.56\n7         Abandoned/Decommissioned       234       0.25           99.81\n8                        Abandoned       175       0.18           99.99\n9 Non functional due to dry season         7       0.01          100.00\n\n\nAs there might be issues performing mathematical calculations with NA labels, we will rename them to unknown.\nThe code below renames the column #status_clean to status_clean, select only the status_clean for manipulation and then replace all na values to unknown.\n\nwpdx_sf_nga <- wpdx_sf %>%\n  rename(status_clean = '#status_clean') %>%\n  select(status_clean) %>%\n  mutate(status_clean = replace_na(status_clean, \"unknown\"))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02.html#filtering-data",
    "href": "In-class_Ex/In-class_Ex02.html#filtering-data",
    "title": "In-class Exercise 2: Geospatial Data Wrangling",
    "section": "4.2 Filtering Data",
    "text": "4.2 Filtering Data\nWith our previous knowledge, we can filter the data to obtain functional proportion counts in each LGA level. We will filter the wpdx_sf_nga dataframes to option functional and non-functional water points.\n\nwpdx_func <- wpdx_sf_nga %>% \n  filter(status_clean %in% \n           c(\"Functional\", \n             \"Functional but not in use\", \n             \"Functional but needs repair\"))\nwpdx_nonfunc <- wpdx_sf_nga %>% \n  filter(status_clean %in%\n          c(\"Abadoned/Decommissioned\", \n            \"Abandoned\",\n            \"Non-Functional due to dry season\",\n            \"Non-Functional\",\n            \"Non functional due to dry season\"))\nwpdx_unknown <- wpdx_sf_nga %>%\n  filter(status_clean == \"unknown\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02.html#point-in-polygon-count",
    "href": "In-class_Ex/In-class_Ex02.html#point-in-polygon-count",
    "title": "In-class Exercise 2: Geospatial Data Wrangling",
    "section": "4.3 Point-in-polygon Count",
    "text": "4.3 Point-in-polygon Count\nUtilising st_intersects() of sf package and lengths, we check where each data point for the water point which fall inside each LGA. We do each calculation separation so we can cross check later to ensure all the values sum to the same total.\n\nnigeria_wp <- nigeria26391 %>%\n  mutate(`total_wp` = lengths(\n    st_intersects(nigeria26391, wpdx_sf_nga))) %>%\n  mutate(`wp_functional` = lengths(\n    st_intersects(nigeria26391, wpdx_func))) %>%\n  mutate(`wp_nonfunctional` = lengths(\n    st_intersects(nigeria26391, wpdx_nonfunc))) %>%\n  mutate(`wp_unknown` = lengths(\n    st_intersects(nigeria26391, wpdx_unknown)))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02.html#saving-the-analytical-data-in-rds-format",
    "href": "In-class_Ex/In-class_Ex02.html#saving-the-analytical-data-in-rds-format",
    "title": "In-class Exercise 2: Geospatial Data Wrangling",
    "section": "4.4 Saving the Analytical Data in rds format",
    "text": "4.4 Saving the Analytical Data in rds format\nIn order to retain the sf data structure for subsequent analysis, we should save the sf dataframe into rds format.\n\nwrite_rds(nigeria_wp, \"Data/rds/nigeria_wp.rds\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02.html#plotting-the-distribution-of-total-water-points-by-lga-in-histogram",
    "href": "In-class_Ex/In-class_Ex02.html#plotting-the-distribution-of-total-water-points-by-lga-in-histogram",
    "title": "In-class Exercise 2: Geospatial Data Wrangling",
    "section": "4.5 Plotting the Distribution of Total Water Points by LGA in Histogram",
    "text": "4.5 Plotting the Distribution of Total Water Points by LGA in Histogram\nNext, we will use mutate() of dplyr package to compute the proportion of Functional and Non- water points.\nThis is given by Functional Proportion = Functional Count / Total Count.\n\nggplot(data = nigeria_wp,\n       aes(x = total_wp)) +\n  geom_histogram(bins = 20,\n                 color = \"black\",\n                 fill = \"light blue\") +\n  geom_vline(aes(xintercept = mean(\n    total_wp, na.rm = T)),\n    color = \"red\",\n    linetype = \"dashed\",\n    size = 0.8) +\n  ggtitle(\"Distribution of total water points by LGA\") +\n  xlab(\"No. of water points\") +\n  ylab(\"No of\\nLGAs\") +\n  theme(axis.title.y = element_text(angle = 0))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03.html",
    "href": "In-class_Ex/In-class_Ex03.html",
    "title": "In-class Exercise 3: Analytical Mapping",
    "section": "",
    "text": "In this in-class exercise, you will gain hands-on experience on using appropriate R methods to plot analytical maps. For the purpose of this exercise, Nigeria water point data prepared during In-class Exercise 2 will be used.\n\n\n\nBy the end of this in-class exercise, you will be able to use appropriate functions of tmap and tidyverse to perform the following tasks:\n\nImporting geospatial data in rds format into R environment.\nCreating cartographic quality choropleth maps by using appropriate tmap functions.\nCreating rate map\nCreating percentile map\nCreating boxmap"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03.html#installing-and-loading-packages",
    "href": "In-class_Ex/In-class_Ex03.html#installing-and-loading-packages",
    "title": "In-class Exercise 3: Analytical Mapping",
    "section": "2.1 Installing and Loading Packages",
    "text": "2.1 Installing and Loading Packages\nFirstly, the code below will check if pacman has been installed. If it has not been installed, R will download and install it, before activating it for use during this session.\n\nif (!require('pacman', character.only = T)){\n  install.packages('pacman')\n}\nlibrary('pacman')\n\nNext, pacman assists us by helping us load R packages that we require, sf, tidyverse and tmap.\n\npacman::p_load(sf, tidyverse, tmap)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03.html#importing-data",
    "href": "In-class_Ex/In-class_Ex03.html#importing-data",
    "title": "In-class Exercise 3: Analytical Mapping",
    "section": "2.2 Importing Data",
    "text": "2.2 Importing Data\nWe want to import the sf dataframe we have cleaned and prepared earlier in class exercise 02.\n\nNGA_wp <- read_rds(\"data/rds/nigeria_wp.rds\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03.html#visualising-distribution-of-non-functional-water-points",
    "href": "In-class_Ex/In-class_Ex03.html#visualising-distribution-of-non-functional-water-points",
    "title": "In-class Exercise 3: Analytical Mapping",
    "section": "2.3 Visualising Distribution of Non-Functional Water Points",
    "text": "2.3 Visualising Distribution of Non-Functional Water Points\nHere, we will plot 2 maps, p1 which shows the functional water points and p2 by total number of water points for side-by-side visualization.\n\np1 <- tm_shape(NGA_wp) +\n  tm_fill(\"wp_functional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\") +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Distribution of functional water points by LGA\",\n            legend.outside = FALSE)\n\n\np2 <- tm_shape(NGA_wp) +\n  tm_fill(\"total_wp\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\") +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Distribution of total water points by LGA\",\n            legend.outside = FALSE)\n\nUsing the tmap_arrange() function, we can arrange the two maps plotted on a single row for side-by-side comparison.\n\ntmap_arrange(p2, p1, nrow = 1)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03.html#deriving-proportion-of-functional-water-points-and-non-functional-water-points",
    "href": "In-class_Ex/In-class_Ex03.html#deriving-proportion-of-functional-water-points-and-non-functional-water-points",
    "title": "In-class Exercise 3: Analytical Mapping",
    "section": "3.1 Deriving Proportion of Functional Water Points and Non-Functional Water Points",
    "text": "3.1 Deriving Proportion of Functional Water Points and Non-Functional Water Points\nWith the code below, we use mutate() to calculate the percentages of functional and nonpfunctional water points.\n\nNGA_wp <- NGA_wp %>%\n  mutate(pct_functional = wp_functional / total_wp) %>%\n  mutate(pct_nonfunctional = wp_nonfunctional / total_wp)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03.html#plotting-map-of-rate",
    "href": "In-class_Ex/In-class_Ex03.html#plotting-map-of-rate",
    "title": "In-class Exercise 3: Analytical Mapping",
    "section": "3.2 Plotting Map of Rate",
    "text": "3.2 Plotting Map of Rate\nUtilising tmap, we can specify the NGA_wp dataframe to colour by pct_functional water points.\n\ntm_shape(NGA_wp) +\n  tm_fill(\"pct_functional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\") +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Rate map of functional water points by LGA\",\n            legend.outside = FALSE)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03.html#percentile-map",
    "href": "In-class_Ex/In-class_Ex03.html#percentile-map",
    "title": "In-class Exercise 3: Analytical Mapping",
    "section": "4.1 Percentile Map",
    "text": "4.1 Percentile Map\nA percentile is a special type of quantile map with the following categories:\n\n0-1%\n1-10%\n10-50%\n50-90%\n90-99%\n99 - 100%\n\nTo create the map, we can set the breakpoints as c(0, 0.01, 0.1, 0.5, 0.9, 0.99, 1). Note that the start and endpoints needs to be included.\n\n4.1.1 Data Preparation\nFirstly, we exclude records with NA using the code below:\n\nNGA_wp <- NGA_wp %>%\n  drop_na()\n\nSecondly, we create a customised classification andextract the values.\n\npercent <- c(0, 0.01, 0.1, 0.5, 0.9, 0.99, 1)\nvar <- NGA_wp[\"pct_functional\"] %>%\n  st_set_geometry(NULL)\nquantile(var[,1], percent)\n\n       0%        1%       10%       50%       90%       99%      100% \n0.0000000 0.0000000 0.2169811 0.4791667 0.8611111 1.0000000 1.0000000 \n\n\n\n\n4.1.2 Function to get variable dataframe\nWith the function below, we can extract a variable out of the sf dataframe as a vector.\n\nget.var <- function(vname, df) {\n  v <- df[vname] %>%\n    st_set_geometry(NULL)\n  v <- unname(v[,1])\n  return(v)\n}\n\n\n\n4.1.3 Percentile Mapping Function\nThis percentmap function allows us to take various inputs and automatically calculate the values and points needed for the percentile map.\nThe use of functions allows us to easily plot percentile maps of other variables flexibly without rewriting the entire code.\n\npercentmap <- function(vnam, df, legtitle = NA, mtitle = \"Percentile Map\"){\n  percent <- c(0, 0.01, 0.1, 0.5, 0.9, 0.99, 1)\n  var <- get.var(vnam, df)\n  bperc <- quantile(var, percent)\n  tm_shape(df) +\n  tm_polygons() +\n  tm_shape(df) +\n    tm_fill(vnam,\n            title = legtitle,\n            breaks = bperc,\n            palette = \"Blues\",\n            labels = c(\"< 1%\", \"1% - 10%\", \"10% - 50%\", \"50% - 90%\", \"90% - 99%\", \"99% - 100%\")) +\n  tm_borders() +\n  tm_layout(main.title = mtitle,\n            title.position = c(\"right\", \"bottom\"))\n  }\n\nPlotting the Percentile Map of functional water points.\n\npercentmap(\"wp_functional\", NGA_wp)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04.html",
    "href": "In-class_Ex/In-class_Ex04.html",
    "title": "In-class Exercise 4",
    "section": "",
    "text": "pacman::p_load(maptools, sf, raster, spatstat, tmap)\n\nThings to learn from this code chunk.\nImporting spatial data\n\nchildcare_sf <- st_read(\"data/Geospatial/child-care-services-geojson.geojson\") %>% \n  st_transform(crs = 3414)\n\nReading layer `child-care-services-geojson' from data source \n  `C:\\Harith-oh\\IS415-Harith\\In-class_Ex\\data\\Geospatial\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nsg_sf <- st_read(dsn = \"data/Geospatial\", layer=\"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `C:\\Harith-oh\\IS415-Harith\\In-class_Ex\\data\\Geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\n\nmpsz_sf <- st_read(dsn = \"data/Geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Harith-oh\\IS415-Harith\\In-class_Ex\\data\\Geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\ntmap_mode('view')\ntm_shape(childcare_sf)+\n  tm_dots()\n\n\n\n\n\n\n\ntmap_mode('view')\ntm_shape(childcare_sf)+\n  tm_dots(alph =0.5,\n          size =0.01) +\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\n\n\n\ntmap_mode('plot')\n\n\nchildcare <- as_Spatial(childcare_sf)\nmpsz <- as_Spatial(mpsz_sf)\nsg <- as_Spatial(sg_sf)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04.html#converting-the-spatial-class-into-generic-sp-format",
    "href": "In-class_Ex/In-class_Ex04.html#converting-the-spatial-class-into-generic-sp-format",
    "title": "In-class Exercise 4",
    "section": "4.5.2 Converting the Spatial* class into generic sp format",
    "text": "4.5.2 Converting the Spatial* class into generic sp format\n\nchildcare_sp <- as(childcare, \"SpatialPoints\")\nsg_sp <- as(sg, \"SpatialPolygons\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04.html#converting-the-generic-sp-format-into-spatstats-ppp-format",
    "href": "In-class_Ex/In-class_Ex04.html#converting-the-generic-sp-format-into-spatstats-ppp-format",
    "title": "In-class Exercise 4",
    "section": "4.5.3 Converting the generic sp format into spatstat’s ppp format",
    "text": "4.5.3 Converting the generic sp format into spatstat’s ppp format\n\nchildcare_ppp <- as(childcare_sp, \"ppp\")\nchildcare_ppp\n\nPlanar point pattern: 1545 points\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n\n\n\nplot(childcare_ppp)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "This study aims to analyse the geographical distribution of functional and non-function water points and their co-locations if any in Osun State, Nigeria by applying appropriate spatial point patterns analysis methods.\n\nTo address the issue of providing a clean and sustainable water supply to the rural community, a global Water Point Data Exchange (WPdx) project has been initiated. The main aim of this initiative is to collect water point-related data from rural areas at the water point or small water scheme level and share the data via WPdx Data Repository, a cloud-based data library."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#data",
    "title": "Take-home Exercise 1",
    "section": "2 Data",
    "text": "2 Data\nThe following data sets will be used in the analysis.\nAspatial Data:\nFor the purpose of this assignment, data from WPdx Global Data Repositories will be used. There are two versions of the data. They are: WPdx-Basic and WPdx+. You are required to use WPdx+ data set.\nGeospatial Data:\nThis study will focus of Osun State, Nigeria. The state boundary GIS data of Nigeria can be downloaded either from The Humanitarian Data Exchange portal or geoBoundaries.\n\n\n\n\n\n\n\n\n\nData\nFormat\nDescription\nSource\n\n\n\n\nNigeria Level-2 Administrative Boundary\nShapefile\n\nHumanitarian Data Exchange(data.humdata.org)\nor\ngeoBoundaries (geoboundaries.org)\n\n\nWPdx Global Data Repositories (WPdx+)\nCSV\n\nwaterpointdata.org"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#install-and-load-packages",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#install-and-load-packages",
    "title": "Take-home Exercise 1",
    "section": "3 Install and load packages",
    "text": "3 Install and load packages\nFirstly, the code below will check if pacman has been installed. If it has not been installed, R will download and install it, before activating it for use during this session.\n\nif (!require('pacman', character.only = T)){\n  install.packages('pacman')\n}\nlibrary('pacman')\n\nTo get started, the following packages will be used for this exercise:\ntidyverse, funModeling, maptools, sf, raster, spatstat & tmap.\n\npacman::p_load(maptools, sf, tidyverse, raster, spatstat, tmap, sfdep, funModeling)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#import-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#import-data",
    "title": "Take-home Exercise 1",
    "section": "4 Import Data",
    "text": "4 Import Data\nImporting & examining the contents of each data set."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#data-wrangling",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#data-wrangling",
    "title": "Take-home Exercise 1",
    "section": "5 Data wrangling",
    "text": "5 Data wrangling\nPre-process and prepare data for analysis."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#importing-geoboundaries-nigeria-level-2-administrative-boundary-dataset",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#importing-geoboundaries-nigeria-level-2-administrative-boundary-dataset",
    "title": "Take-home Exercise 1",
    "section": "4.1 Importing geoBoundaries Nigeria Level-2 Administrative Boundary Dataset",
    "text": "4.1 Importing geoBoundaries Nigeria Level-2 Administrative Boundary Dataset\n\nnigeria = st_read(dsn = \"data/Geospatial\", layer = \"nga_admbnda_adm2_osgof_20190417\")\n\nReading layer `nga_admbnda_adm2_osgof_20190417' from data source \n  `C:\\Harith-oh\\IS415-Harith\\Take-home_Ex\\Take-home_Ex01\\data\\Geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 774 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2.668534 ymin: 4.273007 xmax: 14.67882 ymax: 13.89442\nGeodetic CRS:  WGS 84\n\n\nCheck CRS\n\nst_crs(nigeria)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#checking-for-duplicate-name",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#checking-for-duplicate-name",
    "title": "Take-home Exercise 1",
    "section": "5.2 Checking for Duplicate Name",
    "text": "5.2 Checking for Duplicate Name\n\nnigeria26391$ADM2_EN[duplicated(nigeria26391$ADM2_EN) == TRUE]\n\n[1] \"Bassa\"    \"Ifelodun\" \"Irepodun\" \"Nasarawa\" \"Obi\"      \"Surulere\"\n\n\nTo reduce duplication of LGA names, we will put the state names behind to make it more specific.\n\nnigeria26391$ADM2_EN[94] <- \"Bassa, Kogi\"\nnigeria26391$ADM2_EN[95] <- \"Bassa, Plateau\"\nnigeria26391$ADM2_EN[304] <- \"Ifelodun, Kwara\"\nnigeria26391$ADM2_EN[305] <- \"Ifelodun, Osun\"\nnigeria26391$ADM2_EN[355] <- \"Irepodun, Kwara\"\nnigeria26391$ADM2_EN[356] <- \"Ireopodun, Osun\"\nnigeria26391$ADM2_EN[519] <- \"Nasarawa, Kano\"\nnigeria26391$ADM2_EN[520] <- \"Nasarawa, Nasarawa\"\nnigeria26391$ADM2_EN[546] <- \"Obi, Benue\"\nnigeria26391$ADM2_EN[547] <- \"Obi, Nasarawa\"\nnigeria26391$ADM2_EN[693] <- \"Surulere, Lagos\"\nnigeria26391$ADM2_EN[694] <- \"Surulere, Oyo\"\n\nTo check if the duplication has been resolved.\n\nnigeria26391$ADM2_EN[duplicated(nigeria26391$ADM2_EN) == TRUE]\n\ncharacter(0)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#geospatial-data-cleaning",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#geospatial-data-cleaning",
    "title": "Take-home Exercise 1",
    "section": "5.1 Geospatial Data Cleaning",
    "text": "5.1 Geospatial Data Cleaning\nAs the wpdx sf dataframe consist of many redundant field, we use select() to select the fields which we want to retain.\n\nnigeria26391 <- nigeria26391 %>%\n  dplyr::select(c(3:4, 8:9))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05.html",
    "href": "In-class_Ex/In-class_Ex05.html",
    "title": "In-class_Ex05",
    "section": "",
    "text": "pacman::p_load(tidyverse, tmap, sf, sfdep)\n\nImporting data shapefile for study area\n\nstudyArea <- st_read(dsn = \"data/Geospatial\", \n                layer = \"study_area\") %>%\n  st_transform(crs = 3829)\n\nReading layer `study_area' from data source \n  `C:\\Harith-oh\\IS415-Harith\\In-class_Ex\\data\\Geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 7 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 121.4836 ymin: 25.00776 xmax: 121.592 ymax: 25.09288\nGeodetic CRS:  TWD97\n\n\nImporting data shapefile for stores\n\nstores <- st_read(dsn = \"data/Geospatial\", \n                layer = \"stores\") %>%\n  st_transform(crs = 3829)\n\nReading layer `stores' from data source \n  `C:\\Harith-oh\\IS415-Harith\\In-class_Ex\\data\\Geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 1409 features and 4 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 121.4902 ymin: 25.01257 xmax: 121.5874 ymax: 25.08557\nGeodetic CRS:  TWD97"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05.html#importing-data",
    "href": "In-class_Ex/In-class_Ex05.html#importing-data",
    "title": "In-class_Ex05",
    "section": "Importing Data",
    "text": "Importing Data\n\nstudyArea <- st_read(dsn = \"data/Geospatial\", \n                layer = \"stores\") %>%\n  st_transform(crs = 3829)\n\nReading layer `stores' from data source \n  `C:\\Harith-oh\\IS415-Harith\\In-class_Ex\\data\\Geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 1409 features and 4 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 121.4902 ymin: 25.01257 xmax: 121.5874 ymax: 25.08557\nGeodetic CRS:  TWD97"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05.html#visualizing-the-sf-layers",
    "href": "In-class_Ex/In-class_Ex05.html#visualizing-the-sf-layers",
    "title": "In-class_Ex05",
    "section": "Visualizing the sf layers",
    "text": "Visualizing the sf layers\n\ntmap_mode(\"view\")\ntm_shape(studyArea) +\n  tm_polygons() +\n  tm_shape(stores) +\n  tm_dots(col = \"Name\", \n          size = 0.01,\n          border.col = \"black\",\n          border.lwd = 0.5) +\n  tm_view(set.zoom.limits = c(12, 16))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05.html#local-colocation-quotients-lclq",
    "href": "In-class_Ex/In-class_Ex05.html#local-colocation-quotients-lclq",
    "title": "In-class_Ex05",
    "section": "Local Colocation Quotients (LCLQ)",
    "text": "Local Colocation Quotients (LCLQ)\n\nnb <- include_self(\n  st_knn(st_geometry(stores), 6))\n\n\nwt <- st_kernel_weights(nb,\n                        stores, \n                        \"gaussian\",\n                        adaptive = TRUE)\n\n\nFamilyMart <- stores %>%\n  filter(Name == \"Family Mart\")\nA <- FamilyMart$Name\n\n\nSevenEleven <- stores %>%\n  filter(Name == \"7-Eleven\")\nB <- SevenEleven$Name\n\n\nLCLQ <- local_colocation(A, B, nb, wt , 49)\n\n\nLCLQ_stores <- cbind(stores, LCLQ)\n\n\ntmap_mode(\"view\")\ntm_shape(studyArea) +\n  tm_polygons() +\n  tm_shape(LCLQ_stores) +\n  tm_dots(col = \"X7.Eleven\", \n          size = 0.01,\n          border.col = \"black\",\n          border.lwd = 0.5) +\n  tm_view(set.zoom.limits = c(12, 16))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05.html#visualizing-the-sf-layer",
    "href": "In-class_Ex/In-class_Ex05.html#visualizing-the-sf-layer",
    "title": "In-class_Ex05",
    "section": "Visualizing the sf layer",
    "text": "Visualizing the sf layer\n\ntmap_mode(\"view\")\ntm_shape(studyArea) +\n  tm_polygons() +\n  tm_shape(stores) +\n  tm_dots(col = \"Name\", \n          size = 0.01,\n          border.col = \"black\",\n          border.lwd = 0.5) +\n  tm_view(set.zoom.limits = c(12, 16))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#converting-the-coordinating-reference-system",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#converting-the-coordinating-reference-system",
    "title": "Take-home Exercise 1",
    "section": "4.2 Converting the Coordinating Reference System",
    "text": "4.2 Converting the Coordinating Reference System\nIn the code below, we will convert the Geographic Coordinate Reference System from WGS84 to EPSG:26391 Projected Coordinate System.\n\nnigeria26391 <- st_transform(nigeria, crs = 26391)\n\n\nst_crs(nigeria26391)\n\nCoordinate Reference System:\n  User input: EPSG:26391 \n  wkt:\nPROJCRS[\"Minna / Nigeria West Belt\",\n    BASEGEOGCRS[\"Minna\",\n        DATUM[\"Minna\",\n            ELLIPSOID[\"Clarke 1880 (RGS)\",6378249.145,293.465,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4263]],\n    CONVERSION[\"Nigeria West Belt\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",4,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",4.5,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.99975,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",230738.26,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Engineering survey, topographic mapping.\"],\n        AREA[\"Nigeria - onshore west of 6°30'E, onshore and offshore shelf.\"],\n        BBOX[3.57,2.69,13.9,6.5]],\n    ID[\"EPSG\",26391]]\n\n\nAfter running the code, we can confirm that the data frame has been converted to EPSG:26391 Projected Coordinate System."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#importing-wpdx-aspatial-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#importing-wpdx-aspatial-data",
    "title": "Take-home Exercise 1",
    "section": "4.3 Importing WPdx + Aspatial Data",
    "text": "4.3 Importing WPdx + Aspatial Data\nSince WPdx+ data set is in csv format, we will use read_csv() of readr package to import Water_Point_Data_Exchange_-_PlusWPdx.csv and output it to an R object called wpdx.\n\nwpdx <- read_csv(\"data/Aspatial/Water_Point_Data_Exchange.csv\") %>% filter(`#clean_country_name` == \"Nigeria\")\n\n\nlist(wpdx)\n\n[[1]]\n# A tibble: 95,008 × 70\n   row_id `#source`      #lat_…¹ #lon_…² #repo…³ #stat…⁴ #wate…⁵ #wate…⁶ #wate…⁷\n    <dbl> <chr>            <dbl>   <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 429068 GRID3             7.98    5.12 08/29/… Unknown <NA>    <NA>    Tapsta…\n 2 222071 Federal Minis…    6.96    3.60 08/16/… Yes     Boreho… Well    Mechan…\n 3 160612 WaterAid          6.49    7.93 12/04/… Yes     Boreho… Well    Hand P…\n 4 160669 WaterAid          6.73    7.65 12/04/… Yes     Boreho… Well    <NA>   \n 5 160642 WaterAid          6.78    7.66 12/04/… Yes     Boreho… Well    Hand P…\n 6 160628 WaterAid          6.96    7.78 12/04/… Yes     Boreho… Well    Hand P…\n 7 160632 WaterAid          7.02    7.84 12/04/… Yes     Boreho… Well    Hand P…\n 8 642747 Living Water …    7.33    8.98 10/03/… Yes     Boreho… Well    Mechan…\n 9 642456 Living Water …    7.17    9.11 10/03/… Yes     Boreho… Well    Hand P…\n10 641347 Living Water …    7.20    9.22 03/28/… Yes     Boreho… Well    Hand P…\n# … with 94,998 more rows, 61 more variables: `#water_tech_category` <chr>,\n#   `#facility_type` <chr>, `#clean_country_name` <chr>, `#clean_adm1` <chr>,\n#   `#clean_adm2` <chr>, `#clean_adm3` <chr>, `#clean_adm4` <chr>,\n#   `#install_year` <dbl>, `#installer` <chr>, `#rehab_year` <lgl>,\n#   `#rehabilitator` <lgl>, `#management_clean` <chr>, `#status_clean` <chr>,\n#   `#pay` <chr>, `#fecal_coliform_presence` <chr>,\n#   `#fecal_coliform_value` <dbl>, `#subjective_quality` <chr>, …\n\n\nOur output shows our wpdx tibble data frame consists of 97,478 rows and 74 columns. The useful fields we would be paying attention to is the #lat_deg and #lon_deg columns, which are in the decimal degree format. By viewing the Data Standard on wpdx’s website, we know that the latitude and longitude is in the wgs84 Geographic Coordinate System.\n\n4.3.1 Creating a simple data frame from an Aspatial Data Frame\nAs the geometry is available in wkt in the column New Georeferenced Column, we can use st_as_sfc() to import the geomtry\n\nwpdx$Geometry <- st_as_sfc(wpdx$`New Georeferenced Column`)\n\nAs there is no spatial data information, firstly, we assign the original projection when converting the tibble dataframe to sf. The original is wgs84 which is EPSG:4326.\n\nwpdx_sf <- st_sf(wpdx, crs=4326)\nwpdx_sf\n\nSimple feature collection with 95008 features and 70 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 2.707441 ymin: 4.301812 xmax: 14.21828 ymax: 13.86568\nGeodetic CRS:  WGS 84\n# A tibble: 95,008 × 71\n   row_id `#source`      #lat_…¹ #lon_…² #repo…³ #stat…⁴ #wate…⁵ #wate…⁶ #wate…⁷\n *  <dbl> <chr>            <dbl>   <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 429068 GRID3             7.98    5.12 08/29/… Unknown <NA>    <NA>    Tapsta…\n 2 222071 Federal Minis…    6.96    3.60 08/16/… Yes     Boreho… Well    Mechan…\n 3 160612 WaterAid          6.49    7.93 12/04/… Yes     Boreho… Well    Hand P…\n 4 160669 WaterAid          6.73    7.65 12/04/… Yes     Boreho… Well    <NA>   \n 5 160642 WaterAid          6.78    7.66 12/04/… Yes     Boreho… Well    Hand P…\n 6 160628 WaterAid          6.96    7.78 12/04/… Yes     Boreho… Well    Hand P…\n 7 160632 WaterAid          7.02    7.84 12/04/… Yes     Boreho… Well    Hand P…\n 8 642747 Living Water …    7.33    8.98 10/03/… Yes     Boreho… Well    Mechan…\n 9 642456 Living Water …    7.17    9.11 10/03/… Yes     Boreho… Well    Hand P…\n10 641347 Living Water …    7.20    9.22 03/28/… Yes     Boreho… Well    Hand P…\n# … with 94,998 more rows, 62 more variables: `#water_tech_category` <chr>,\n#   `#facility_type` <chr>, `#clean_country_name` <chr>, `#clean_adm1` <chr>,\n#   `#clean_adm2` <chr>, `#clean_adm3` <chr>, `#clean_adm4` <chr>,\n#   `#install_year` <dbl>, `#installer` <chr>, `#rehab_year` <lgl>,\n#   `#rehabilitator` <lgl>, `#management_clean` <chr>, `#status_clean` <chr>,\n#   `#pay` <chr>, `#fecal_coliform_presence` <chr>,\n#   `#fecal_coliform_value` <dbl>, `#subjective_quality` <chr>, …\n\n\nNext, we then convert the projection to the appropriate decimal based projection system.\n\nwpdx_sf <- wpdx_sf %>%\n  st_transform(crs = 26391)\n\n\nwpdx_spdf <- as_Spatial(wpdx_sf)\nwpdx_spdf\n\nclass       : SpatialPointsDataFrame \nfeatures    : 95008 \nextent      : 32536.82, 1292096, 33461.24, 1091052  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=4 +lon_0=4.5 +k=0.99975 +x_0=230738.26 +y_0=0 +a=6378249.145 +rf=293.465 +towgs84=-92,-93,122,0,0,0,0 +units=m +no_defs \nvariables   : 70\nnames       : row_id,                                     X.source, X.lat_deg,  X.lon_deg,          X.report_date, X.status_id, X.water_source_clean, X.water_source_category, X.water_tech_clean, X.water_tech_category, X.facility_type, X.clean_country_name, X.clean_adm1, X.clean_adm2, X.clean_adm3, ... \nmin values  :  10732, Federal Ministry of Water Resources, Nigeria, 4.3018117,   2.707441, 01/01/2010 12:00:00 AM,          No,             Borehole,             Piped Water,          Hand Pump,             Hand Pump,        Improved,              Nigeria,         Abia,    Aba North,           NA, ... \nmax values  : 681838,                                  WaterAid UK, 13.865675, 14.2182849, 12/31/2014 12:00:00 AM,         Yes,       Protected Well,                    Well,           Tapstand,              Tapstand,        Improved,              Nigeria,      Zamfara,         Zuru,           NA, ..."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#understanding-field-names",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#understanding-field-names",
    "title": "Take-home Exercise 1",
    "section": "6.1 Understanding Field Names",
    "text": "6.1 Understanding Field Names\nFirst, let us have a look at the #status_clean column which stores the information about Functional and Non-Functional data points. The code below returns all values that were used in the column.\n\nfreq(data = wpdx_sf,\n     input = '#status_clean')\n\n\n\n\n                     #status_clean frequency percentage cumulative_perc\n1                       Functional     45883      48.29           48.29\n2                   Non-Functional     29385      30.93           79.22\n3                             <NA>     10656      11.22           90.44\n4      Functional but needs repair      4579       4.82           95.26\n5 Non-Functional due to dry season      2403       2.53           97.79\n6        Functional but not in use      1686       1.77           99.56\n7         Abandoned/Decommissioned       234       0.25           99.81\n8                        Abandoned       175       0.18           99.99\n9 Non functional due to dry season         7       0.01          100.00\n\n\nAs there might be issues performing mathematical calculations with NA labels, we will rename them to unknown.\nThe code below renames the column #status_clean to status_clean, select only the status_clean for manipulation and then replace all na values to unknown.\n\nwpdx_sf_nga <- wpdx_sf %>%\n  rename(status_clean = '#status_clean') %>%\n  dplyr::select(status_clean) %>%\n  mutate(status_clean = replace_na(status_clean, \"unknown\"))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#filtering-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#filtering-data",
    "title": "Take-home Exercise 1",
    "section": "6.2 Filtering Data",
    "text": "6.2 Filtering Data\nWith our previous knowledge, we can filter the data to obtain functional proportion counts in each LGA level. We will filter the wpdx_sf_nga dataframes to option functional and non-functional water points.\n\nwpdx_func <- wpdx_sf_nga %>% \n  filter(status_clean %in% \n           c(\"Functional\", \n             \"Functional but not in use\", \n             \"Functional but needs repair\"))\nwpdx_nonfunc <- wpdx_sf_nga %>% \n  filter(status_clean %in%\n          c(\"Abandoned/Decommissioned\", \n            \"Abandoned\",\n            \"Non-Functional due to dry season\",\n            \"Non-Functional\",\n            \"Non functional due to dry season\"))\nwpdx_unknown <- wpdx_sf_nga %>%\n  filter(status_clean == \"unknown\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#point-in-polygon-count",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#point-in-polygon-count",
    "title": "Take-home Exercise 1",
    "section": "6.3 Point-in-polygon Count",
    "text": "6.3 Point-in-polygon Count\nUtilising st_intersects() of sf package and lengths, we check where each data point for the water point which fall inside each LGA. We do each calculation separation so we can cross check later to ensure all the values sum to the same total.\n\nnigeria_wp <- nigeria26391 %>%\n  mutate(`total_wp` = lengths(\n    st_intersects(nigeria26391, wpdx_sf_nga))) %>%\n  mutate(`wp_functional` = lengths(\n    st_intersects(nigeria26391, wpdx_func))) %>%\n  mutate(`wp_nonfunctional` = lengths(\n    st_intersects(nigeria26391, wpdx_nonfunc))) %>%\n  mutate(`wp_unknown` = lengths(\n    st_intersects(nigeria26391, wpdx_unknown)))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#saving-the-analytical-data-in-rds-format",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#saving-the-analytical-data-in-rds-format",
    "title": "Take-home Exercise 1",
    "section": "6.4 Saving the Analytical Data in rds format",
    "text": "6.4 Saving the Analytical Data in rds format\nIn order to retain the sf data structure for subsequent analysis, we should save the sf dataframe into rds format.\n\nwrite_rds(nigeria_wp, \"Data/rds/nigeria_wp.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#plotting-the-distribution-of-total-water-points-by-lga-in-histogram",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#plotting-the-distribution-of-total-water-points-by-lga-in-histogram",
    "title": "Take-home Exercise 1",
    "section": "6.5 Plotting the Distribution of Total Water Points by LGA in Histogram",
    "text": "6.5 Plotting the Distribution of Total Water Points by LGA in Histogram\nNext, we will use mutate() of dplyr package to compute the proportion of Functional and Non- water points.\nThis is given by Functional Proportion = Functional Count / Total Count.\n\nggplot(data = nigeria_wp,\n       aes(x = total_wp)) +\n  geom_histogram(bins = 20,\n                 color = \"black\",\n                 fill = \"light blue\") +\n  geom_vline(aes(xintercept = mean(\n    total_wp, na.rm = T)),\n    color = \"red\",\n    linetype = \"dashed\",\n    size = 0.8) +\n  ggtitle(\"Distribution of total water points by LGA\") +\n  xlab(\"No. of water points\") +\n  ylab(\"No of\\nLGAs\") +\n  theme(axis.title.y = element_text(angle = 0))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#exploratory-spatial-data-analysis-esda",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#exploratory-spatial-data-analysis-esda",
    "title": "Take-home Exercise 1",
    "section": "7 Exploratory Spatial Data Analysis (ESDA)",
    "text": "7 Exploratory Spatial Data Analysis (ESDA)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#import-the-data-saved-in-rds",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#import-the-data-saved-in-rds",
    "title": "Take-home Exercise 1",
    "section": "7.1 Import the data saved in rds",
    "text": "7.1 Import the data saved in rds\nWe want to import the sf dataframe we have cleaned and prepared earlier\n\nNGA_wp <- read_rds(\"Data/rds/nigeria_wp.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#visualising-distribution-of-non-functional-water-points",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#visualising-distribution-of-non-functional-water-points",
    "title": "Take-home Exercise 1",
    "section": "7.2 Visualising Distribution of Non-Functional Water Points",
    "text": "7.2 Visualising Distribution of Non-Functional Water Points\nHere, we will plot 2 maps, p1 which shows the functional water points and p2 by total number of water points for side-by-side visualization.\n\np1 <- tm_shape(NGA_wp) +\n  tm_fill(\"wp_functional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\") +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Distribution of functional water points by LGA\",\n            legend.outside = FALSE)\n\n\np2 <- tm_shape(NGA_wp) +\n  tm_fill(\"total_wp\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\") +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Distribution of total water points by LGA\",\n            legend.outside = FALSE)\n\n\ntmap_arrange(p2, p1, nrow = 1)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#visualising-the-sf-layers",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#visualising-the-sf-layers",
    "title": "Take-home Exercise 1",
    "section": "8 Visualising the sf layers",
    "text": "8 Visualising the sf layers\nIt is to ensure that they have been imported properly and been projected on an appropriate projection system.\n\ntmap_mode(\"view\")\ntm_shape(NGA_wp) +\n  tm_polygons() +\n  tm_dots()\n\n\n\n\n\n\n\nNGA <- as_Spatial(NGA_wp)\n\n\nwpdx_sp <- as(wpdx_spdf, \"SpatialPoints\")\nNGA_sp <- as(NGA, \"SpatialPolygons\")\n\n\nosun = NGA[NGA@data$ADM1_EN == \"Osun\",]\n\nTo plot\n\nplot(osun, main = \"Osun\")\n\n\n\n\nNext, conversion of SpatialPolygonsDataFrame layers into generic spatialpolygons layers\n\nosun_sp = as(osun, \"SpatialPolygons\")\n\nCreating owin object to convert the above spatialpolygons objects into owin objects that is required by spatstat\n\nosun_owin = as(osun_sp, \"owin\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#converting-the-generic-sp-format-into-spatstats-ppp-format",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#converting-the-generic-sp-format-into-spatstats-ppp-format",
    "title": "Take-home Exercise 1",
    "section": "8.2 Converting the generic sp format into spatstat’s ppp format",
    "text": "8.2 Converting the generic sp format into spatstat’s ppp format\nNow, we will use as.ppp() function of spatstat to convert the spatial data into spatstat’s ppp object format.\n\nwpdx_ppp <- as(wpdx_sp, \"ppp\")\nwpdx_ppp\n\nPlanar point pattern: 95008 points\nwindow: rectangle = [32536.8, 1292096.3] x [33461.2, 1091051.6] units\n\n\n\nsummary(wpdx_ppp)\n\nPlanar point pattern:  95008 points\nAverage intensity 7.132208e-08 points per square unit\n\nCoordinates are given to 2 decimal places\ni.e. rounded to the nearest multiple of 0.01 units\n\nWindow: rectangle = [32536.8, 1292096.3] x [33461.2, 1091051.6] units\n                    (1260000 x 1058000 units)\nWindow area = 1.3321e+12 square units\n\n\n\nany(duplicated(wpdx_ppp))\n\n[1] FALSE"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#combining-osun-water-points",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#combining-osun-water-points",
    "title": "Take-home Exercise 1",
    "section": "8.3 Combining osun water points",
    "text": "8.3 Combining osun water points\n\nnigeria_osun_PPP = wpdx_ppp[osun_owin]\n\nrescale() function is used to transform the unit of measurement from metre to kilometre\n\nnigeria_osun_PPP.km = rescale(nigeria_osun_PPP, 1000, \"km\")\n\nPlotting the Osun water point study area\n\nplot(nigeria_osun_PPP.km, main = \"Osun\")\n\n\n\n\nVisualising the SF layer for Osun\n\ntmap_mode(\"view\")\ntm_shape(osun) +\n  tm_polygons() +\n  tm_dots(size = 0.01,\n          border.col = \"black\",\n          border.lwd = 0.5)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#computing-kde-of-osun-state",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#computing-kde-of-osun-state",
    "title": "Take-home Exercise 1",
    "section": "9.1 Computing KDE of Osun State",
    "text": "9.1 Computing KDE of Osun State\nThe code below will be used to compute the KDE of Osun. bw.diggle method is used to derive the bandwidth\n\nplot(density(nigeria_osun_PPP.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Osun\")\n\n\n\n\nComputing fixed bandwidth KDE\n\nplot(density(nigeria_osun_PPP.km,\n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Osun\")\n\n\n\n\nThe advantage of kernel density map over point map is that it spreads the known quantity in color shades of waterpoints for each location in Osun State of Nigeria. Whereas for Kernel point, it only provides the pointer of waterpoints for each location in Osun State and does not state the number unless clicked.\n\nwpdx_ppp <- as(wpdx_sp, \"ppp\")\nwpdx_ppp\n\nPlanar point pattern: 95008 points\nwindow: rectangle = [32536.8, 1292096.3] x [33461.2, 1091051.6] units\n\n\n\nsummary(wpdx_ppp)\n\nPlanar point pattern:  95008 points\nAverage intensity 7.132208e-08 points per square unit\n\nCoordinates are given to 2 decimal places\ni.e. rounded to the nearest multiple of 0.01 units\n\nWindow: rectangle = [32536.8, 1292096.3] x [33461.2, 1091051.6] units\n                    (1260000 x 1058000 units)\nWindow area = 1.3321e+12 square units\n\n\n\nany(duplicated(wpdx_ppp))\n\n[1] FALSE\n\n\n\nosun1 <- tm_shape(osun) +\n  tm_fill(\"wp_functional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\") +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Distribution of functional water points by LGA\",\n            legend.outside = FALSE)\n\n\nosun2 <- tm_shape(osun) +\n  tm_fill(\"wp_nonfunctional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\") +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Distribution of total water points by LGA\",\n            legend.outside = FALSE)\n\n\ntmap_arrange(osun2, osun1, nrow = 1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nkde_osun_bw <- density(nigeria_osun_PPP,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \n\n\nplot(kde_osun_bw)\n\n\n\n\n\nosun_bw <- bw.diggle(nigeria_osun_PPP)\nosun_bw\n\n   sigma \n217.8511 \n\n\n\nosun_PPP.km <- rescale(nigeria_osun_PPP, 1000, \"km\")\n\n\nkde_osun_PPP.bw <- density(nigeria_osun_PPP.km, sigma1=bw.diggle, edge=TRUE, kernel=\"gaussian\")\nplot(kde_osun_PPP.bw)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#second-spatial-point-analysis",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#second-spatial-point-analysis",
    "title": "Take-home Exercise 1",
    "section": "10 Second Spatial Point Analysis",
    "text": "10 Second Spatial Point Analysis"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#performing-clarks-evans-test-of-osun-state",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#performing-clarks-evans-test-of-osun-state",
    "title": "Take-home Exercise 1",
    "section": "10.1 Performing Clarks Evans Test of Osun State",
    "text": "10.1 Performing Clarks Evans Test of Osun State\nIn this section, we will perform the Clark-Evans test of aggregation for a spatial point pattern by using clarkevans.test() of statspat.\nThe test hypotheses are:\nHo = The distribution of waterpoints are randomly distributed.\nH1= The distribution of waterpoints are not randomly distributed.\nThe 95% confidence interval will be used.\n\nclarkevans.test(nigeria_osun_PPP,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Monte Carlo test based on 999 simulations of CSR with fixed n\n\ndata:  nigeria_osun_PPP\nR = 0.42836, p-value = 0.002\nalternative hypothesis: two-sided\n\n\nGiven the p value of 0.002 which is lesser than 0.05 of 95% confidence interval, we can conclude that the null hypothesis (H0) should be rejected and the distribution of waterpoints are not randomly distributed."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#analysing-second-spatial-point-using-l-function",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#analysing-second-spatial-point-using-l-function",
    "title": "Take-home Exercise 1",
    "section": "10.2 Analysing Second Spatial Point using L function",
    "text": "10.2 Analysing Second Spatial Point using L function\nIn this section, second spatial point L-function will be using Lest() of spatstat package. Monta carlo simulation test will be used using envelope() of spatstat package."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#computing-l-function-estimation",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#computing-l-function-estimation",
    "title": "Take-home Exercise 1",
    "section": "10.2.1 Computing L Function Estimation",
    "text": "10.2.1 Computing L Function Estimation\n\n#L_ck = Lest(nigeria_osun_PPP, correction = \"Ripley\")\n#plot(L_ck, . -r ~ r, \n    # ylab= \"L(d)-r\", xlab = \"d(m)\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#performing-complete-spatial-random-test",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#performing-complete-spatial-random-test",
    "title": "Take-home Exercise 1",
    "section": "10.2.2 Performing Complete Spatial Random Test",
    "text": "10.2.2 Performing Complete Spatial Random Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of Water Point at Osun State are randomly distributed.\nH1= The distribution of Water Point at Osun State are not randomly distributed.\nThe null hypothesis will be rejected if p-value if smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing\n\n#L_ck.csr <- envelope(nigeria_osun_PPP, Lest, nsim = 39, rank = 1, glocal=TRUE)\n\n\n#plot(L_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"L(d)-r\")\n\n\nAs shown in the chart, given the L_ck.csr plotted graph exited the envelope this shows that it is lesser than 0.05 of 95% confidence interval, H0 is rejected and we can conclude that the distribution of waterpoints are not randomly distributed."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#local-colocation-quotients-lclq",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#local-colocation-quotients-lclq",
    "title": "Take-home Exercise 1",
    "section": "11 Local Colocation Quotients (LCLQ)",
    "text": "11 Local Colocation Quotients (LCLQ)\nNote:\nThe following code chunks above are commented to allow the take_home_ex1.html file (over 70mb) to commit and push to my github repository. The images from section 11 onwards are statically pasted to reduce the file size.\nBefore we perform the local colocation quotients, We will the wpdx_sf_nga dataframes to include both functional and non-functional water points only.\n\n wpdx_lclq <- wpdx_sf_nga %>% \n   filter(status_clean %in% \n            c(\"Functional\",\n             \"Non-Functional\"))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#visualizing-the-sf-layer",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#visualizing-the-sf-layer",
    "title": "Take-home Exercise 1",
    "section": "11.1 Visualizing the sf layer",
    "text": "11.1 Visualizing the sf layer\nFirstly, we want to visualise and observe how the sf layer will look like with the water points in osun.\n\n#tmap_mode(\"view\")\n#tm_shape(osun) +\n  #tm_polygons() +\n  #tm_shape(wpdx_lclq) +\n  #tm_dots(col = \"status_clean\", \n          #size = 0.01,\n          #border.col = \"black\",\n          #border.lwd = 0.5)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#applying-local-colocation-quotients-lclq",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#applying-local-colocation-quotients-lclq",
    "title": "Take-home Exercise 1",
    "section": "11.2 Applying Local Colocation Quotients (LCLQ)",
    "text": "11.2 Applying Local Colocation Quotients (LCLQ)\nIn this section, we will perform the Local Colocation Quotients (LCLQ) to measure the concentration of the waterpoints in Osun by using local_colocation.\nAfter visualising the sf layers, it looks like most waterpoints in the Osun state are highly concentrated. Thus, the test hypotheses are:\nHo = The concentration of the waterpoints in the Osun generally low\nH1= The concentration of the waterpoints in the Osun state are generally high\nTo perform the Local Colocation Quotients (LCLQ), we will first identify the k nearest neighbors for given point geometry.\n\n#nb <- include_self(\n  #st_knn(st_geometry(wpdx_lclq), 6))\n\nAfter that, we will create a weights list using a kernel function.\n\n#wt <- st_kernel_weights(nb,\n                        #wpdx_lclq, \n                        #\"gaussian\",\n                        #adaptive = TRUE)\n\nWe will filter functional and non-functional from the wpdx_lclq whereby Functional will be A and Nonfunctional will be B.\n\n#Functional <- wpdx_lclq %>%\n  #(status_clean == \"Functional\")\n#A <- Functional$status_clean\n\n\n#NonFunctional <- wpdx_lclq %>%\n  #(status_clean == \"Non-Functional\")\n#B <- NonFunctional$status_clean\n\nWe will use the local_colocation() to calculate LCLQ.\n\n#LCLQ <- local_colocation(A, B, nb, wt , 20)\n\nAfter that, we will use the column bind function to merge two data frames together given that the number of rows in both the data frames are equal.\n\n#LCLQ_sf_nga <- cbind(wpdx_lclq, LCLQ)\n\nFinally, we will use the tmap() to visualise the results of LCLQ.\n\n#tmap_mode(\"view\")\n#tm_shape(osun) +\n  #tm_polygons() +\n  #tm_shape(LCLQ_sf_nga) +\n  #tm_dots(col = \"Non.Functional\", \n          #size = 0.01,\n          #border.col = \"black\",\n          #border.lwd = 0.5)\n\n\nFrom the visualisation above, we can conclude that there are many ‘missing’ water points in Osun which implies that the points on the upper side of Osun State are more concentrated. Thus, we will reject H1 for this case since the concentration are generally low.\nAfter performing the ‘clark evans test’, ‘L function’ and the ‘local colocation quotients’, we can conclude that H0 is rejected, the functional and non functional water points in Osun State are not randomly distributed with low concentration where the upper part of Osun state are slightly more concentrated.\nEnd of take home exercise 1"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#ing-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex1.html#ing-data",
    "title": "Take-home Exercise 1",
    "section": "6.2 ing Data",
    "text": "6.2 ing Data\nWith our previous knowledge, we can the data to obtain functional proportion counts in each LGA level. We will the wpdx_sf_nga dataframes to option functional and non-functional water points.\n\nwpdx_func <- wpdx_sf_nga %>% \n  filter(status_clean %in% \n           c(\"Functional\", \n             \"Functional but not in use\", \n             \"Functional but needs repair\"))\nwpdx_nonfunc <- wpdx_sf_nga %>% \n  filter(status_clean %in%\n          c(\"Abadoned/Decommissioned\", \n            \"Abandoned\",\n            \"Non-Functional due to dry season\",\n            \"Non-Functional\",\n            \"Non functional due to dry season\"))\nwpdx_unknown <- wpdx_sf_nga %>%\n  filter(status_clean == \"unknown\")"
  }
]